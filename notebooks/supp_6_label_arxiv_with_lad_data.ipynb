{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Label arXiv with LAD data\n",
    "\n",
    "We will use this in our subnational analysis of DL research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = pd.read_csv('../data/external/grid/grid.csv')\n",
    "grid_lat_lon = pd.read_csv('../data/external/grid/full_tables/addresses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is to fix a bug in the fuzzy matching - we matched UCL papers with UCL Australia instead of UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucl = grid.loc[grid['Name']=='University College London'].reset_index(drop=True)\n",
    "\n",
    "ucl.columns = ['institute_id','institute_name','institute_city','institute_state','institute_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucl_address = grid_lat_lon.set_index('grid_id').loc[ucl['institute_id'][0]]\n",
    "ucl['institute_lat'] = ucl_address['lat']\n",
    "ucl['institute_lon'] = ucl_address['lng']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_matched = pd.read_csv('../data/external/1_8_2019_paper_institute_locations.csv',compression='zip',dtype={'article_id':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_matched_w_data = grid_matched.dropna(axis=0,subset=['institute_lat','institute_lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucl_papers = grid_matched_w_data.loc[grid_matched_w_data['institute_name']=='UCL Australia']\n",
    "\n",
    "ucl_papers_without_geo = ucl_papers.iloc[:,:4]\n",
    "ucl_papers_without_geo['institute_name']='University College London'\n",
    "\n",
    "ucl_papers_geo = pd.merge(ucl_papers_without_geo,ucl,left_on='institute_name',right_on='institute_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_matched_clean = pd.concat([grid_matched.loc[grid_matched['institute_name']!='UCL Australia'].reset_index(drop=True),\n",
    "                                ucl_papers_geo],axis=0)\n",
    "\n",
    "grid_matched_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lads = gp.read_file('../data/external/lad_shape/Local_Authority_Districts_December_2018_Boundaries_GB_BFC.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_matched_clean.to_csv(f'../data/external/{today_str}_papers_institution_ucl_cleaned.csv',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_shapes = gp.read_file('../data/external/admin/ne_10m_admin_1_states_provinces.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge (all countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a lookup between cities and IDs\n",
    "# We crate the city_country variable to avoid mistakes with duplicate city names (Cambridge, England vs Cambridge Mass)\n",
    "grid_matched_clean['city_country'] = [x+'_'+y if pd.isnull(x)==False else np.nan for \n",
    "                                      x,y in zip(grid_matched_clean['institute_city'],grid_matched_clean['institute_country'])]\n",
    "\n",
    "city_coords = grid_matched_clean.dropna(axis=0,subset=['institute_city','institute_country','institute_lat','institute_lon']).drop_duplicates(\n",
    "    ['city_country','institute_country'])[['city_country','institute_country','institute_lat','institute_lon']].reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This is to create the geodf\n",
    "# grid_df = gp.GeoDataFrame(\n",
    "#     grid_matched_clean, geometry=[Point(x, y) for x, y in zip(grid_matched_clean['institute_lon'], grid_matched_clean['institute_lat'])])\n",
    "\n",
    "\n",
    "city_df = gp.GeoDataFrame(\n",
    "    city_coords, geometry=[Point(x, y) for x, y in zip(city_coords['institute_lon'], city_coords['institute_lat'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproject\n",
    "lads = lads.to_crs({'init':'epsg:4326'})\n",
    "admin_shapes = admin_shapes.to_crs({'init':'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp_joined = gp.sjoin(lads,grid_df,how='left',op='contains')\n",
    "\n",
    "sp_joined = gp.sjoin(city_df,admin_shapes,how='left',op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_joined[['city_country','name_en']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_geo = pd.merge(grid_matched_clean,sp_joined[['city_country','name_en','geometry','iso_a2']],left_on='city_country',right_on='city_country')\n",
    "papers_geo.to_csv(f'../data/processed/{today_str}_grid_geo_admin_all.csv',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAD merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproject\n",
    "lads = lads.to_crs({'init':'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This is to create the geodf\n",
    "grid_df = gp.GeoDataFrame(\n",
    "    grid_matched_clean, geometry=[Point(x, y) for x, y in zip(grid_matched_clean['institute_lon'], grid_matched_clean['institute_lat'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df = grid_df.loc[grid_df['is_multinational']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_joined = gp.sjoin(lads,grid_df,how='left',op='contains')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papers_geo.to_csv(f'../data/processed/{today_str}_grid_geo_admin_all.csv',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_grouped = pd.concat([sp_joined.groupby('article_id')[var].apply(lambda x: list(x)) for var in ['lad18cd','lad18nm']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_grouped.to_json(f'../data/processed/{today_str}_arxiv_lads.json',orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ids = set((grid_df.loc[grid_df['institute_country']=='United Kingdom'])['article_id'])-set(sp_joined['article_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_matched_clean.loc[grid_matched_clean['article_id']=='0905.0201'][['institute_name','institute_country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
