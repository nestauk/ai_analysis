{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrich arXiv / MAG data\n",
    "\n",
    "* Enrich the data with fields and gender information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebook_preamble.ipy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load arXiv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arx = pd.read_csv('../data/external/1_8_2019_arxiv_mag.csv',compression='zip',dtype={'paper_id':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arx.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label with topics and with gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topics\n",
    "\n",
    "These topics were calculated for our women in AI analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/external/28_4_2019_community_lookup_names.json') as infile:\n",
    "    \n",
    "    field_comms = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately the MAG data doesn't have the paper topics\n",
    "\n",
    "arx_pre = pd.read_csv('../data/external/7_5_2019_papers_final.csv',compression='zip',\n",
    "                     converters={'arxiv_categories':literal_eval,'discipline':literal_eval},dtype={'article_id':str})[['article_id',\n",
    "                                                                                                'arxiv_categories','abstract']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we should use them to classify papers into categories\n",
    "arx_pre['fields'] = [set([field_comms[x] for x in categories]) for categories in arx_pre['arxiv_categories']]\n",
    "\n",
    "arx_pre_pure_discipline = arx_pre.loc[[len(x)==1 for x in arx_pre['fields']]]\n",
    "\n",
    "arx_pre_pure_discipline['disc'] = [list(x)[0] for x in arx_pre_pure_discipline['fields']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load lda_pipeline.py\n",
    "from gensim import corpora, models\n",
    "from string import punctuation\n",
    "from string import digits\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Characters to drop\n",
    "drop_characters = re.sub('-','',punctuation)+digits\n",
    "\n",
    "#Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('English')\n",
    "\n",
    "#Stem functions\n",
    "from nltk.stem import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def clean_tokenise(string,drop_characters=drop_characters,stopwords=stop):\n",
    "    '''\n",
    "    Takes a string and cleans (makes lowercase and removes stopwords)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "\n",
    "    #Lowercase\n",
    "    str_low = string.lower()\n",
    "    \n",
    "    \n",
    "    #Remove symbols and numbers\n",
    "    str_letters = re.sub('[{drop}]'.format(drop=drop_characters),'',str_low)\n",
    "    \n",
    "    \n",
    "    #Remove stopwords\n",
    "    clean = [x for x in str_letters.split(' ') if (x not in stop) & (x!='')]\n",
    "    \n",
    "    return(clean)\n",
    "\n",
    "\n",
    "class CleanTokenize():\n",
    "    '''\n",
    "    This class takes a list of strings and returns a tokenised, clean list of token lists ready\n",
    "    to be processed with the LdaPipeline\n",
    "    \n",
    "    It has a clean method to remove symbols and stopwords\n",
    "    \n",
    "    It has a bigram method to detect collocated words\n",
    "    \n",
    "    It has a stem method to stem words\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,corpus):\n",
    "        '''\n",
    "        Takes a corpus (list where each element is a string)\n",
    "        '''\n",
    "        \n",
    "        #Store\n",
    "        self.corpus = corpus\n",
    "        \n",
    "    def clean(self,drop=drop_characters,stopwords=stop):\n",
    "        '''\n",
    "        Removes strings and stopwords, \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        cleaned = [clean_tokenise(doc,drop_characters=drop,stopwords=stop) for doc in self.corpus]\n",
    "        \n",
    "        self.tokenised = cleaned\n",
    "        return(self)\n",
    "    \n",
    "    def stem(self):\n",
    "        '''\n",
    "        Optional: stems words\n",
    "        \n",
    "        '''\n",
    "        #Stems each word in each tokenised sentence\n",
    "        stemmed = [[stemmer.stem(word) for word in sentence] for sentence in self.tokenised]\n",
    "    \n",
    "        self.tokenised = stemmed\n",
    "        return(self)\n",
    "        \n",
    "    \n",
    "    def bigram(self,threshold=10):\n",
    "        '''\n",
    "        Optional Create bigrams.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #Colocation detector trained on the data\n",
    "        phrases = models.Phrases(self.tokenised,threshold=threshold)\n",
    "        \n",
    "        bigram = models.phrases.Phraser(phrases)\n",
    "        \n",
    "        self.tokenised = bigram[self.tokenised]\n",
    "        \n",
    "        return(self)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "class LdaPipeline():\n",
    "    '''\n",
    "    This class processes lists of keywords.\n",
    "    How does it work?\n",
    "    -It is initialised with a list where every element is a collection of keywords\n",
    "    -It has a method to filter keywords removing those that appear less than a set number of times\n",
    "    \n",
    "    -It has a method to process the filtered df into an object that gensim can work with\n",
    "    -It has a method to train the LDA model with the right parameters\n",
    "    -It has a method to predict the topics in a corpus\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,corpus):\n",
    "        '''\n",
    "        Takes the list of terms\n",
    "        '''\n",
    "        \n",
    "        #Store the corpus\n",
    "        self.tokenised = corpus\n",
    "        \n",
    "    def filter(self,minimum=5):\n",
    "        '''\n",
    "        Removes keywords that appear less than 5 times.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #Load\n",
    "        tokenised = self.tokenised\n",
    "        \n",
    "        #Count tokens\n",
    "        token_counts = pd.Series([x for el in tokenised for x in el]).value_counts()\n",
    "        \n",
    "        #Tokens to keep\n",
    "        keep = token_counts.index[token_counts>minimum]\n",
    "        \n",
    "        #Filter\n",
    "        tokenised_filtered = [[x for x in el if x in keep] for el in tokenised]\n",
    "        \n",
    "        #Store\n",
    "        self.tokenised = tokenised_filtered\n",
    "        self.empty_groups = np.sum([len(x)==0 for x in tokenised_filtered])\n",
    "        \n",
    "        return(self)\n",
    "    \n",
    "    def clean(self):\n",
    "        '''\n",
    "        Remove symbols and numbers\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    def process(self):\n",
    "        '''\n",
    "        This creates the bag of words we use in the gensim analysis\n",
    "        \n",
    "        '''\n",
    "        #Load the list of keywords\n",
    "        tokenised = self.tokenised\n",
    "        \n",
    "        #Create the dictionary\n",
    "        dictionary = corpora.Dictionary(tokenised)\n",
    "        \n",
    "        #Create the Bag of words. This converts keywords into ids\n",
    "        corpus = [dictionary.doc2bow(x) for x in tokenised]\n",
    "        \n",
    "        self.corpus = corpus\n",
    "        self.dictionary = dictionary\n",
    "        return(self)\n",
    "        \n",
    "    def tfidf(self):\n",
    "        '''\n",
    "        This is optional: We extract the term-frequency inverse document frequency of the words in\n",
    "        the corpus. The idea is to identify those keywords that are more salient in a document by normalising over\n",
    "        their frequency in the whole corpus\n",
    "        \n",
    "        '''\n",
    "        #Load the corpus\n",
    "        corpus = self.corpus\n",
    "        \n",
    "        #Fit a TFIDF model on the data\n",
    "        tfidf = models.TfidfModel(corpus)\n",
    "        \n",
    "        #Transform the corpus and save it\n",
    "        self.corpus = tfidf[corpus]\n",
    "        \n",
    "        return(self)\n",
    "    \n",
    "    def fit_lda(self,num_topics=20,passes=5,iterations=75,random_state=1803):\n",
    "        '''\n",
    "        \n",
    "        This fits the LDA model taking a set of keyword arguments.\n",
    "        #Number of passes, iterations and random state for reproducibility. We will have to consider\n",
    "        reproducibility eventually.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #Load the corpus\n",
    "        corpus = self.corpus\n",
    "        \n",
    "        #Train the LDA model with the parameters we supplied\n",
    "        lda = models.LdaModel(corpus,id2word=self.dictionary,\n",
    "                              num_topics=num_topics,passes=passes,iterations=iterations,random_state=random_state)\n",
    "        \n",
    "        #Save the outputs\n",
    "        self.lda_model = lda\n",
    "        self.lda_topics = lda.show_topics(num_topics=num_topics)\n",
    "        \n",
    "\n",
    "        return(self)\n",
    "    \n",
    "    def predict_topics(self):\n",
    "        '''\n",
    "        This predicts the topic mix for every observation in the corpus\n",
    "        \n",
    "        '''\n",
    "        #Load the attributes we will be working with\n",
    "        lda = self.lda_model\n",
    "        corpus = self.corpus\n",
    "        \n",
    "        #Now we create a df\n",
    "        predicted = lda[corpus]\n",
    "        \n",
    "        #Convert this into a dataframe\n",
    "        predicted_df = pd.concat([pd.DataFrame({x[0]:x[1] for x in topics},\n",
    "                                              index=[num]) for num,topics in enumerate(predicted)]).fillna(0)\n",
    "        \n",
    "        self.predicted_df = predicted_df\n",
    "        \n",
    "        return(self)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load text_classifier.py\n",
    "# CLasses\n",
    "\n",
    "#One class for text classification based on text inputs\n",
    "\n",
    "class TextClassification():\n",
    "    '''\n",
    "    This class takes a corpus (could be a list of strings or a tokenised corpus) and a target (could be multiclass or single class).\n",
    "    \n",
    "    When it is initialised it vectorises the list of tokens using sklearn's count vectoriser.\n",
    "    \n",
    "    It has a grid search method that takes a list of models and parameters and trains the model.\n",
    "    \n",
    "    It returns the output of grid search for diagnosis\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,corpus,target):\n",
    "        '''\n",
    "        \n",
    "        Initialise. The class will recognise if we are feeding it a list of strings or a list of\n",
    "        tokenised documents and vectorise accordingly. \n",
    "        \n",
    "        It will also recognise is this a multiclass or one class problem based on the dimensions of the target array\n",
    "        \n",
    "        Later on, it will use control flow to modify model parameters depending on the type of data we have\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #Is this a multiclass classification problem or a single class classification problem?\n",
    "        if target.shape[1]>1:\n",
    "            self.mode = 'multiclass'\n",
    "            \n",
    "        else:\n",
    "            self.mode = 'single_class'\n",
    "    \n",
    "    \n",
    "        #Store the target\n",
    "        self.Y = target\n",
    "    \n",
    "        #Did we feed the model a bunch of strings or a list of tokenised docs? If the latter, we clean and tokenise.\n",
    "        \n",
    "        if type(corpus[0])==str:\n",
    "            corpus = CleanTokenize(corpus).clean().bigram().tokenised\n",
    "            \n",
    "        #Turn every list of tokens into a string for count vectorising\n",
    "        corpus_string =  [' '.join(words) for words in corpus]\n",
    "        \n",
    "        \n",
    "        #And then we count vectorise in a hacky way.\n",
    "        count_vect = CountVectorizer(stop_words='english',min_df=5).fit(corpus_string)\n",
    "        \n",
    "        #Store the features\n",
    "        self.X = count_vect.transform(corpus_string)\n",
    "        \n",
    "        #Store the count vectoriser (we will use it later on for prediction on new data)\n",
    "        self.count_vect = count_vect\n",
    "        \n",
    "    def grid_search(self,models):\n",
    "        '''\n",
    "        The grid search method takes a list with models and their parameters and it does grid search crossvalidation.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #Load inputs and targets into the model\n",
    "        Y = self.Y\n",
    "        X = self.X\n",
    "        \n",
    "        if self.mode=='multiclass':\n",
    "            '''\n",
    "            If the model is multiclass then we need to add some prefixes to the model paramas\n",
    "            \n",
    "            '''\n",
    "        \n",
    "            for mod in models:\n",
    "                #Make ovr\n",
    "                mod[0] = OneVsRestClassifier(mod[0])\n",
    "                \n",
    "                #Add the estimator prefix\n",
    "                mod[1] = {'estimator__'+k:v for k,v in mod[1].items()}\n",
    "                \n",
    "        \n",
    "        #Container with results\n",
    "        results = []\n",
    "\n",
    "        #For each model, run the analysis.\n",
    "        for num,mod in enumerate(models):\n",
    "            print(num)\n",
    "\n",
    "            #Run the classifier\n",
    "            clf = GridSearchCV(mod[0],mod[1])\n",
    "\n",
    "            #Fit\n",
    "            clf.fit(X,Y)\n",
    "\n",
    "            #Append results\n",
    "            results.append(clf)\n",
    "        \n",
    "        self.results = results\n",
    "        return(self)\n",
    "\n",
    "    \n",
    "#Class to visualise the outputs of multilabel models.\n",
    "\n",
    "#I call it OrangeBrick after YellowBrick, the package for ML output visualisation \n",
    "#(which currently doesn't support multilabel classification)\n",
    "\n",
    "\n",
    "class OrangeBrick():\n",
    "    '''\n",
    "    This class takes a df with the true classes for a multilabel classification exercise and produces some charts visualising findings.\n",
    "    \n",
    "    The methods include:\n",
    "    \n",
    "        .confusion_stack: creates a stacked barchart with the confusion matrices stacked by category, sorting classes by performance\n",
    "        .prec_rec: creates a barchart showing each class precision and recall;\n",
    "        #Tobe done: Consider mixes between classes?\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,true_labels,predicted_labels,var_names):\n",
    "        '''\n",
    "        Initialise with a true labels, predicted labels and the variable names\n",
    "        '''\n",
    "         \n",
    "        self.true_labels = true_labels\n",
    "        self.predicted_labels = predicted_labels\n",
    "        self.var_names = var_names\n",
    "    \n",
    "    def make_metrics(self):\n",
    "        '''\n",
    "        Estimates performance metrics (for now just confusion charts by class and precision/recall scores for the 0.5 \n",
    "        decision rule.\n",
    "        \n",
    "        '''\n",
    "        #NB in a confusion matrix in SKlearn the X axis indicates the predicted class and the Y axis indicates the ground truth.\n",
    "        #This means that:\n",
    "            #cf[0,0]-> TN\n",
    "            #cf[1,1]-> TP\n",
    "            #cf[0,1]-> FN (prediction is false, groundtruth is true)\n",
    "            #cf[1,0]-> FP (prediction is true, ground truth is false)\n",
    "\n",
    "\n",
    "\n",
    "        #Predictions and true labels\n",
    "        true_labels = self.true_labels\n",
    "        pred_labels = self.predicted_labels\n",
    "\n",
    "        #Variable names\n",
    "        var_names = self.var_names\n",
    "\n",
    "        #Store confusion matrices\n",
    "        score_store = []\n",
    "\n",
    "\n",
    "        for num in np.arange(len(var_names)):\n",
    "\n",
    "            #This is the confusion matrix\n",
    "            cf = confusion_matrix(pred_labels[:,num],true_labels[:,num])\n",
    "\n",
    "            #This is a melted confusion matrix\n",
    "            melt_cf = pd.melt(pd.DataFrame(cf).reset_index(drop=False),id_vars='index')['value']\n",
    "            melt_cf.index = ['true_negative','false_positive','false_negative','true_positive']\n",
    "            melt_cf.name = var_names[num]\n",
    "            \n",
    "            #Order variables to separate failed vs correct predictions\n",
    "            melt_cf = melt_cf.loc[['true_positive','true_negative','false_positive','false_negative']]\n",
    "\n",
    "            #We are also interested in precision and recall\n",
    "            prec = cf[1,1]/(cf[1,1]+cf[1,0])\n",
    "            rec = cf[1,1]/(cf[1,1]+cf[0,1])\n",
    "\n",
    "            prec_rec = pd.Series([prec,rec],index=['precision','recall'])\n",
    "            prec_rec.name = var_names[num]\n",
    "            score_store.append([melt_cf,prec_rec])\n",
    "    \n",
    "        self.score_store = score_store\n",
    "        \n",
    "        return(self)\n",
    "    \n",
    "    def confusion_chart(self,ax):\n",
    "        '''\n",
    "        Plot the confusion charts\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #Visualise confusion matrix outputs\n",
    "        cf_df = pd.concat([x[0] for x in self.score_store],1)\n",
    "\n",
    "        #This ranks categories by the error rates\n",
    "        failure_rate = cf_df.apply(lambda x: x/x.sum(),axis=0).loc[['false' in x for x in cf_df.index]].sum().sort_values(\n",
    "            ascending=False).index\n",
    "\n",
    "        \n",
    "        #Plot and add labels\n",
    "        cf_df.T.loc[failure_rate,:].plot.bar(stacked=True,ax=ax,width=0.8,cmap='Accent')\n",
    "\n",
    "        ax.legend(bbox_to_anchor=(1.01,1))\n",
    "        #ax.set_title('Stacked confusion matrix for disease areas',size=16)\n",
    "    \n",
    "    \n",
    "    def prec_rec_chart(self,ax):\n",
    "        '''\n",
    "        \n",
    "        Plot a precision-recall chart\n",
    "        \n",
    "        '''\n",
    "    \n",
    "\n",
    "        #Again, we sort them here to assess model performance in different disease areas\n",
    "        prec_rec = pd.concat([x[1] for x in self.score_store],1).T.sort_values('precision')\n",
    "        prec_rec.plot.bar(ax=ax)\n",
    "\n",
    "        #Add legend and title\n",
    "        ax.legend(bbox_to_anchor=(1.01,1))\n",
    "        #ax.set_title('Precision and Recall by disease area',size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML imports\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore',UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(888)\n",
    "\n",
    "random_set= random.sample(list(np.arange(0,len(arx_pre_pure_discipline))),100000)\n",
    "\n",
    "training = arx_pre_pure_discipline.iloc[random_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the corpus\n",
    "corpus = list(training['abstract'])\n",
    "\n",
    "#We use a utility function to create a df for a one vs rest classification\n",
    "target = pd.get_dummies(training['disc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run grid search with these model parameters\n",
    "my_models = [\n",
    "    [RandomForestClassifier(),\n",
    "     {'class_weight':['balanced',None],'min_samples_leaf':[1,5]}],\n",
    "    \n",
    "    [LogisticRegression(),\n",
    "     {'class_weight':['balanced',None],'penalty':['l1','l2'],\n",
    "      'C':[0.1,1,100]}]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict groups\n",
    "\n",
    "#Initialise the TextClassification class\n",
    "arx_t = TextClassification(corpus,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arx_t.grid_search(my_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check scores and best estimators\n",
    "for res in arx_t.results:\n",
    "    print(res.best_score_)\n",
    "    print(res.best_estimator_)\n",
    "    \n",
    "    #This is the best estimator\n",
    "best_est = arx_t.results[1].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arx_diag = OrangeBrick(true_labels=np.array(target),\n",
    "                      predicted_labels=best_est.predict(arx_t.X),\n",
    "                      var_names=target.columns).make_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=2,figsize=(10,7.5))\n",
    "\n",
    "arx_diag.confusion_chart(ax=ax[0])\n",
    "arx_diag.prec_rec_chart(ax=ax[1])\n",
    "\n",
    "#fig.suptitle('Model evaluation for GTR disciplines',y=1.01,size=16)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we classify all arxiv projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arxiv_processed = arx_t.count_vect.transform(arx['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arxiv_predicted = pd.DataFrame(best_est.predict_proba(all_arxiv_processed),columns=['field_'+x for x in target.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arxiv = pd.concat([arx,all_arxiv_predicted],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arxiv['top_field'] = all_arxiv[all_arxiv_predicted.columns].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_with_gender = pd.read_csv('../data/external/28_4_2019_papers_gender_stats.csv',compression='zip',dtype={'article_id':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arx_final = pd.merge(all_arxiv,papers_with_gender,left_on='paper_id',right_on='article_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arx_final.to_csv(f'../data/processed/{today_str}_arxiv_enriched.csv',compression='zip')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
