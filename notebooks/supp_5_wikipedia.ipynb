{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Wikipedia articles\n",
    "\n",
    "Here I want to get text that relates to various concepts of interest such as \n",
    "\n",
    "* AI ethics\n",
    "* Military applications of AI\n",
    "* Concerns with computing infrastructure and big data\n",
    "* Surveillance and espionage\n",
    "\n",
    "Maybe I would get these articles from arXiv itself?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mwclient import Site\n",
    "\n",
    "# site = Site('en.wikipedia.org')\n",
    "\n",
    "#page = site.pages['Surveillance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "categories = [['Ethics','Morality','Legality'],['Infrastructure','Big data','Computing'],['Surveillance','Espionage','Spy'],\n",
    "              ['Warfare','Weapon','Army'],['Health','Medicine'],['Theory','Basic research'],['Product (business)','Applied science','Technology']]\n",
    "\n",
    "for c in categories:\n",
    "    \n",
    "    topic_text = []\n",
    "    \n",
    "    for el in c:\n",
    "        \n",
    "        out = wikipedia.page(el).summary\n",
    "        topic_text.append(out)\n",
    "        \n",
    "    texts.append(' '.join(topic_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_clean = [re.sub('\\n',' ',x) for x in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_out = pd.DataFrame([[name,text] for name,text in zip(['ethics','infrastructure','surveillance','warfare','health','theory','application'],texts_clean)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_out.to_csv(f'../data/external/{today_str}_wiki_text.csv',index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
